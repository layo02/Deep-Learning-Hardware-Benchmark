{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a29d4bb8",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "[I.   Benchmark with Floating-point Operations Per Second (FLOPS) Calculator](#Test01)\n",
    "\n",
    "[II.  Benchmark with MNIST dataset](#Test02)\n",
    "\n",
    "[III. Benchmark with Zalando MNIST dataset](#Test02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a101ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Import required libraries:\n",
    "#\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "##\n",
    "# Import functions:\n",
    "#\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D, Dropout, Dense\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import mixed_precision\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras_flops import get_flops\n",
    "from utils import process_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddbf6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Recheck to see if GPU will be available:\n",
    "#\n",
    "gpu = len(tensorflow.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8939257",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Set up the precision target:\n",
    "#\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5440191",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Implement the model architecture:\n",
    "#\n",
    "backend.clear_session()\n",
    "try:\n",
    "    os.mkdir('classifiers')\n",
    "except:\n",
    "    pass\n",
    "full_name = 'Model A'\n",
    "\n",
    "convolution_base = VGG19(weights = 'imagenet', include_top = False, input_shape = (32,32,3))\n",
    "\n",
    "###\n",
    "# Use this command to load the weights if you cannot access to the Internet.\n",
    "# Remember to replace <file_name> with the actual filename.\n",
    "# convolution_base = VGG19(weights = 'weights/<file_name>.h5', include_top = False, input_shape = (32,32,3))\n",
    "\n",
    "convolution_base.trainable = False\n",
    "###\n",
    "model = Sequential()\n",
    "model.add(convolution_base)\n",
    "x = model.output\n",
    "###\n",
    "x = Conv2D(128, kernel_size=(3,3), activation = 'relu', padding = 'same')(x)\n",
    "x = Conv2D(128, kernel_size=(3,3), activation = 'relu', padding = 'same')(x)\n",
    "x = Conv2D(128, kernel_size=(3,3), activation = 'relu', padding = 'same')(x)\n",
    "x = Conv2D(128, kernel_size=(3,3), activation = 'relu', padding = 'same')(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "###\n",
    "x = Dense(4096, activation = 'relu', kernel_regularizer = regularizers.l1_l2(l1 = 1e-5, l2 = 1e-4),\n",
    "          bias_regularizer = regularizers.l2(1e-4),\n",
    "          activity_regularizer = regularizers.l2(1e-5))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(2048, activation = 'relu', kernel_regularizer = regularizers.l1_l2(l1 = 1e-5, l2 = 1e-4),\n",
    "          bias_regularizer = regularizers.l2(1e-4),\n",
    "          activity_regularizer = regularizers.l2(1e-5))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(128, activation = 'relu', kernel_regularizer = regularizers.l1_l2(l1 = 1e-5, l2 = 1e-4),\n",
    "          bias_regularizer = regularizers.l2(1e-4),\n",
    "          activity_regularizer = regularizers.l2(1e-5))(x)\n",
    "out = Dense(10, activation = 'softmax')(x)\n",
    "finalModel = Model(inputs = model.input, outputs = out)\n",
    "\n",
    "##\n",
    "# Compile the model with defined optimizer and metrics:\n",
    "#\n",
    "opt = Adam(learning_rate = 0.001, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-07)\n",
    "finalModel.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy', 'Precision', 'Recall'])\n",
    "\n",
    "##\n",
    "# Extract the best model based on validation accuracy:\n",
    "#\n",
    "#filepath = \"classifiers/%s-{epoch:02d}-{val_accuracy:.4f}-MNIST.hdf5\"%full_name\n",
    "#checkpoint = ModelCheckpoint(filepath, monitor = 'val_accuracy', save_best_only = True, mode = 'max')\n",
    "#callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3842f1",
   "metadata": {},
   "source": [
    "# I. Benchmark with FLoating-point Operations Per Second (FLOPS) Calculator <a name = 'Test01'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cf289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Calculate FLOPS:\n",
    "#\n",
    "flops = get_flops(finalModel, batch_size = 1)\n",
    "print(\"FLOPS: %.2f G\" %(flops / 10**9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a893b7",
   "metadata": {},
   "source": [
    "# II. Benchmark with MNIST dataset <a name = 'Test02'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0a659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Load the MNIST dataset:\n",
    "#\n",
    "\n",
    "data_location = int(input('Select the option to load data (0 = from the server; 1 = manually from the directory): '))\n",
    "\n",
    "if data_location == 0:\n",
    "    X, y = fetch_openml('mnist_784', version = 1, return_X_y = True, as_frame = False)\n",
    "    \n",
    "    ##\n",
    "    # Convert the input data into RGB image type and resize the resolution to 32x32:\n",
    "    #\n",
    "    X = process_mnist.resize_mnist(X, 32, 28)\n",
    "    X = np.stack((X,) * 3, axis = -1)\n",
    "    \n",
    "    ##\n",
    "    # One-hot encoding the output labels:\n",
    "    #\n",
    "    y = to_categorical(y, num_classes = 10)\n",
    "    \n",
    "elif data_location == 1:\n",
    "    X_train, y_train = process_mnist.load_mnist('data/mnist', kind = 'train')\n",
    "    X_test, y_test = process_mnist.load_mnist('data/mnist', kind = 't10k')\n",
    "    \n",
    "    ##\n",
    "    # Convert the input data into RGB image type and resize the resolution to 32x32:\n",
    "    #\n",
    "    X_train = process_mnist.resize_mnist(X_train, 32, 28)\n",
    "    X_train = np.stack((X_train,) * 3, axis = -1)\n",
    "\n",
    "    X_test = process_mnist.resize_mnist(X_test, 32, 28)\n",
    "    X_test = np.stack((X_test,) * 3, axis = -1)\n",
    "\n",
    "    ##\n",
    "    # One-hot encoding the output labels:\n",
    "    #\n",
    "    y_train = to_categorical(y_train, num_classes = 10)\n",
    "    y_test = to_categorical(y_test, num_classes = 10)\n",
    "else:\n",
    "    print('Invalid selection!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec82d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Sanity check for input and output dimensions:\n",
    "#\n",
    "if data_location == 0:\n",
    "    assert X.shape == (70000, 32, 32, 3), \"X should have a dimension of (70000, 32, 32, 3)!\"\n",
    "    assert y.shape == (70000,10), \"y should have a dimension of (70000,10)!\"\n",
    "elif data_location == 1:\n",
    "    assert X_train.shape == (60000, 32, 32, 3), \"X should have a dimension of (60000, 32, 32, 3)\"\n",
    "    assert y_train.shape == (60000,10), \"y should have a dimension of (60000,10)\"\n",
    "    assert X_test.shape == (10000, 32, 32, 3), \"X should have a dimension of (60000, 32, 32, 3)\"\n",
    "    assert y_test.shape == (10000,10), \"y should have a dimension of (60000,10)\"\n",
    "else:\n",
    "    print('Invalid selection!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0509a0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Prepare the train and test subsets:\n",
    "#\n",
    "if data_location == 0:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = None, test_size = 10000)\n",
    "else:\n",
    "    None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f8fd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Train the model and store the execution time for evaluation:\n",
    "#\n",
    "start = time.time()\n",
    "history = finalModel.fit(X_train, y_train, epochs = 100, verbose = 1,\n",
    "                         shuffle = True, validation_data = (X_test, y_test))\n",
    "end = time.time()\n",
    "runtime_mnist = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa2b14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Visualize the train/validation accuracy and loss after the training duration:\n",
    "#\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title(\"MNIST Accuracy\")\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc = 'upper left')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "###\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"MNIST Loss\")\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc = 'upper left')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3c1022",
   "metadata": {},
   "source": [
    "## II. Benchmark with Zalando MNIST dataset <a name = 'Test02'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521ecb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Load the Zalando MNIST dataset:\n",
    "#\n",
    "X_train, y_train = process_mnist.load_mnist('data/fashion', kind = 'train')\n",
    "X_test, y_test = process_mnist.load_mnist('data/fashion', kind = 't10k')\n",
    "\n",
    "\n",
    "##\n",
    "# Convert the input data into RGB image type and resize the resolution to 32x32:\n",
    "#\n",
    "X_train = process_mnist.resize_mnist(X_train, 32, 28)\n",
    "X_train = np.stack((X_train,) * 3, axis = -1)\n",
    "X_test = process_mnist.resize_mnist(X_test, 32, 28)\n",
    "X_test = np.stack((X_test,) * 3, axis = -1)\n",
    "\n",
    "##\n",
    "# One-hot encoding the output labels:\n",
    "#\n",
    "y_train = to_categorical(y_train, num_classes = 10)\n",
    "y_test = to_categorical(y_test, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31d2e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Sanity check for input and output dimensions:\n",
    "#\n",
    "assert X_train.shape == (60000,32,32,3), \"X_train should have a dimension of (60000,32,32,3)!\"\n",
    "assert X_test.shape == (10000,32,32,3), \"X_test should have a dimension of (10000,32,32,3)!\"\n",
    "assert y_train.shape == (60000,10), \"y_train should have a dimension of (60000,10)\"\n",
    "assert y_test.shape == (10000,10), \"y_test should have a dimension of (10000,10)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764336d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Extract the best model based on validation accuracy:\n",
    "#\n",
    "#filepath = \"classifiers/%s-{epoch:02d}-{val_accuracy:.4f}-fashion.hdf5\"%full_name\n",
    "#checkpoint = ModelCheckpoint(filepath, monitor = 'val_accuracy', save_best_only = True, mode = 'max')\n",
    "#callbacks_list = [checkpoint]\n",
    "\n",
    "###\n",
    "# Train the model and store the execution time for evaluation:\n",
    "#\n",
    "start = time.time()\n",
    "history = finalModel.fit(X_train, y_train, epochs = 100, verbose = 1,\n",
    "                         shuffle = True, validation_data = (X_test, y_test))\n",
    "end = time.time()\n",
    "runtime_fashion = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5592ad40",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Visualize the train/validation accuracy and loss after the training duration:\n",
    "#\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title(\"Zalando Accuracy\")\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc = 'upper left')\n",
    "plt.grid(True)\n",
    "plt.show() \n",
    "###\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"Zalando Loss\")\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc = 'upper left')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61633b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Visualize the execution time on each dataset, respectively: \n",
    "#\n",
    "values = [round(runtime_mnist,0) , round(runtime_fashion,0)]\n",
    "names = ['MNIST', 'Zalando']\n",
    "\n",
    "plt.bar(names, values)\n",
    "plt.ylabel('Time')\n",
    "plt.grid(True)\n",
    "\n",
    "for index, data in enumerate(values):\n",
    "    plt.text(x = index , y = data + 1 , s = f\"{data}\" , fontdict = dict(fontsize = 12), ha = 'center')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac3b57d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_gpu] *",
   "language": "python",
   "name": "conda-env-tensorflow_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
