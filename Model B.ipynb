{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "[I.  Benchmark with MNIST dataset](#Test01)\n",
    "\n",
    "[II. Benchmark with Zalando MNIST dataset](#Test02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Import required libraries:\n",
    "#\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import time\n",
    "import visualkeras\n",
    "\n",
    "\n",
    "##\n",
    "# Import functions:\n",
    "#\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.applications import DenseNet201\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D, Dropout, Dense\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import ImageFont\n",
    "from utils import process_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Benchmark with MNIST dataset <a name = 'Test01'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Load the MNIST dataset:\n",
    "#\n",
    "X, y = fetch_openml('mnist_784', version = 1, return_X_y = True, as_frame = False)\n",
    "\n",
    "##\n",
    "# Convert the input data into RGB image type and resize the resolution to 32x32:\n",
    "#\n",
    "X = process_mnist.resize_mnist(X, 32, 28)\n",
    "X = np.stack((X,) * 3, axis = -1)\n",
    "\n",
    "##\n",
    "# One-hot encoding the output labels:\n",
    "#\n",
    "y = to_categorical(y, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Sanity check for input and output dimensions:\n",
    "#\n",
    "assert X.shape == (70000, 32, 32, 3), \"X should have a dimension of (70000, 32, 32, 3)\"\n",
    "assert y.shape == (70000,10), \"y should have a dimension of (70000,10)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Prepare the train and test subsets:\n",
    "#\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = None, test_size = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Implement the model architecture:\n",
    "#\n",
    "try:\n",
    "    os.mkdir('classifiers')\n",
    "except:\n",
    "    pass\n",
    "full_name = 'Model B'\n",
    "\n",
    "convolution_base = DenseNet201(weights = 'imagenet', include_top = False, \n",
    "                         input_shape = (300,300,3))\n",
    "convolution_base.trainable = False\n",
    "###\n",
    "model = Sequential()\n",
    "model.add(convolution_base)\n",
    "x = model.output\n",
    "###\n",
    "x = Conv2D(128, kernel_size=(3,3), activation = 'relu', padding = 'same')(x)\n",
    "x = Conv2D(128, kernel_size=(3,3), activation = 'relu', padding = 'same')(x)\n",
    "x = Conv2D(128, kernel_size=(3,3), activation = 'relu', padding = 'same')(x)\n",
    "x = Conv2D(128, kernel_size=(3,3), activation = 'relu', padding = 'same')(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "###\n",
    "x = Dense(4096, activation = 'relu', kernel_regularizer = regularizers.l1_l2(l1 = 1e-5, l2 = 1e-4),\n",
    "          bias_regularizer = regularizers.l2(1e-4),\n",
    "          activity_regularizer = regularizers.l2(1e-5))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(2048, activation = 'relu', kernel_regularizer = regularizers.l1_l2(l1 = 1e-5, l2 = 1e-4),\n",
    "          bias_regularizer = regularizers.l2(1e-4),\n",
    "          activity_regularizer = regularizers.l2(1e-5))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(128, activation = 'relu', kernel_regularizer = regularizers.l1_l2(l1 = 1e-5, l2 = 1e-4),\n",
    "          bias_regularizer = regularizers.l2(1e-4),\n",
    "          activity_regularizer = regularizers.l2(1e-5))(x)\n",
    "out = Dense(10, activation = 'softmax')(x)\n",
    "finalModel = Model(inputs = model.input, outputs = out)\n",
    "\n",
    "##\n",
    "# Visualize the model:\n",
    "#\n",
    "finalModel.summary()\n",
    "font = ImageFont.truetype(\"arial.ttf\", 20)\n",
    "visualkeras.layered_view(finalModel, legend = True, font = font).show()\n",
    "\n",
    "##\n",
    "# Compile the model with defined optimizer and metrics:\n",
    "#\n",
    "opt = Adam(learning_rate = 0.001, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-07)\n",
    "finalModel.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy', 'Precision', 'Recall'])\n",
    "\n",
    "##\n",
    "# Extract the best model based on validation accuracy:\n",
    "#\n",
    "#filepath = \"classifiers/%s-{epoch:02d}-{val_accuracy:.4f}.hdf5\"%full_name\n",
    "#checkpoint = ModelCheckpoint(filepath, monitor = 'val_accuracy', save_best_only = True, mode = 'max')\n",
    "#callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Train the model and store the execution time for evaluation:\n",
    "#\n",
    "start = time.time()\n",
    "history = finalModel.fit(datagen.flow(Xtrain, Ytrain, batch_size = 12), \n",
    "                         epochs = 100, verbose = 1, shuffle = True, callbacks = callbacks_list, validation_data = (Xval, Yval))\n",
    "end = time.time()\n",
    "runtime_mnist = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Visualize the train/validation accuracy and loss after the training duration:\n",
    "#\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title(\"MNIST Accuracy\")\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc = 'upper left')\n",
    "plt.show()\n",
    "###\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"MNIST Loss\")\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc = 'upper left')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Benchmark with Zalando MNIST dataset <a name = 'Test02'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Load the Zalando MNIST dataset:\n",
    "#\n",
    "X_train, y_train = process_mnist.load_mnist('data/fashion', kind = 'train')\n",
    "X_test, y_test = process_mnist.load_mnist('data/fashion', kind = 't10k')\n",
    "\n",
    "\n",
    "##\n",
    "# Convert the input data into RGB image type and resize the resolution to 32x32:\n",
    "#\n",
    "X_train = process_mnist.resize_mnist(X_train, 32, 28)\n",
    "X_train = np.stack((X_train,) * 3, axis = -1)\n",
    "X_test = process_mnist.resize_mnist(X_test, 32, 28)\n",
    "X_test = np.stack((X_test,) * 3, axis = -1)\n",
    "\n",
    "##\n",
    "# One-hot encoding the output labels:\n",
    "#\n",
    "y_train = to_categorical(y_train, num_classes = 10)\n",
    "y_test = to_categorical(y_test, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Sanity check for input and output dimensions:\n",
    "#\n",
    "assert X_train.shape == (60000,32,32,3), \"X_train should have a dimension of (60000,32,32,3)!\"\n",
    "assert X_test.shape == (10000,32,32,3), \"X_test should have a dimension of (10000,32,32,3)!\"\n",
    "assert y_train.shape == (60000,10) \"y_train should have a dimension of (60000,10)\"\n",
    "assert y_test.shape == (10000,10) \"y_test should have a dimension of (10000,10)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Extract the best model based on validation accuracy:\n",
    "#\n",
    "#filepath = \"classifiers/%s-{epoch:02d}-{val_accuracy:.4f}-fashion.hdf5\"%full_name\n",
    "#checkpoint = ModelCheckpoint(filepath, monitor = 'val_accuracy', save_best_only = True, mode = 'max')\n",
    "#callbacks_list = [checkpoint]\n",
    "\n",
    "###\n",
    "# Train the model and store the execution time for evaluation:\n",
    "#\n",
    "start = time.time()\n",
    "history = finalModel.fit(X_train, y_train, epochs = 100, verbose = 1,\n",
    "                         shuffle = True, validation_data = (X_test, y_test))\n",
    "end = time.time()\n",
    "runtime_fashion = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Visualize the train/validation accuracy and loss after the training duration:\n",
    "#\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title(\"Zalando Accuracy\")\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc = 'upper left')\n",
    "plt.show()\n",
    "###\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"Zalando Loss\")\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc = 'upper left')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Visualize the execution time on each dataset, respectively: \n",
    "#\n",
    "plt.bar(['MNIST', 'Zalando'], [runtime_MNIST, runtime_fashion])\n",
    "plt.ylabel('Time')\n",
    "plt.legend(['MNIST', 'Zalando'], loc = 'upper left')\n",
    "plt.grid(on)\n",
    "\n",
    "for index, data in enumerate([runtime_MNIST, runtime_fashion]):\n",
    "    plt.text(x = index , y = data + 1 , s = f\"{data}\" , fontdict = dict(fontsize=20), ha = 'center')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Visualize the model:\n",
    "#\n",
    "finalModel.summary()\n",
    "font = ImageFont.truetype(\"arial.ttf\", 32)\n",
    "visualkeras.layered_view(finalModel, legend = True, to_file = 'Model A.png').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
