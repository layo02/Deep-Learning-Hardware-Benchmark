{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "[I.  Benchmark with MNIST dataset](#Test01)\n",
    "\n",
    "[II. Benchmark with Zalando MNIST dataset](#Test02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "##\n",
    "# Import required libraries:\n",
    "#\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "##\n",
    "# Import functions:\n",
    "#\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import mixed_precision\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import process_mnist, models, profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "##\n",
    "# Recheck to see if GPU will be available:\n",
    "#\n",
    "device_name = tensorflow.test.gpu_device_name()\n",
    "if not device_name:\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "##\n",
    "# Set up the precision target:\n",
    "#\n",
    "policy = tensorflow.keras.mixed_precision.experimental.Policy('float32')\n",
    "tensorflow.keras.mixed_precision.experimental.set_policy(policy)\n",
    "\n",
    "##\n",
    "# Test for precision target:\n",
    "#\n",
    "if not policy:\n",
    "    raise SystemError('Error when executing this cell block.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Benchmark with MNIST dataset <a name = 'Test01'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "##\n",
    "# Load the MNIST dataset:\n",
    "#\n",
    "\n",
    "data_location = int(input('Select the option to load data (0 = from the server; 1 = manually from the directory): '))\n",
    "\n",
    "if data_location == 0:\n",
    "    X, y = fetch_openml('mnist_784', version = 1, return_X_y = True, as_frame = False)\n",
    "    \n",
    "    ##\n",
    "    # Convert the input data into RGB image type and resize the original resolution to 28x28:\n",
    "    #\n",
    "    X = process_mnist.resize_mnist(X, 28, 28, 32, 32)\n",
    "    X = np.stack((X,) * 3, axis = -1)\n",
    "    \n",
    "    ##\n",
    "    # One-hot encoding the output labels:\n",
    "    #\n",
    "    y = to_categorical(y, num_classes = 10)\n",
    "    \n",
    "elif data_location == 1:\n",
    "    X_train, y_train = process_mnist.load_mnist('data/mnist', kind = 'train')\n",
    "    X_test, y_test = process_mnist.load_mnist('data/mnist', kind = 't10k')\n",
    "    \n",
    "    ##\n",
    "    # Convert the input data into RGB image type and resize the resolution to 28x28:\n",
    "    #\n",
    "    X_train = process_mnist.resize_mnist(X_train, 28, 28, 32, 32)\n",
    "    X_train = np.stack((X_train,) * 3, axis = -1)\n",
    "\n",
    "    X_test = process_mnist.resize_mnist(X_test, 28, 28, 32, 32)\n",
    "    X_test = np.stack((X_test,) * 3, axis = -1)\n",
    "\n",
    "    ##\n",
    "    # One-hot encoding the output labels:\n",
    "    #\n",
    "    y_train = to_categorical(y_train, num_classes = 10)\n",
    "    y_test = to_categorical(y_test, num_classes = 10)\n",
    "else:\n",
    "    print('Invalid selection!')\n",
    "    \n",
    "##\n",
    "# Test for data loading:\n",
    "#\n",
    "if (not np.any(X_train)) or (not np.any(X_test)) or (not np.any(y_train)) or (not np.any(y_test)):\n",
    "    raise SystemError('Error when executing this cell block.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "##\n",
    "# Sanity check for input and output dimensions:\n",
    "#\n",
    "if data_location == 0:\n",
    "    assert X.shape == (70000, 32, 32, 3), \"X should have a dimension of (70000, 32, 32, 3)!\"\n",
    "    assert y.shape == (70000,10), \"y should have a dimension of (70000,10)!\"\n",
    "elif data_location == 1:\n",
    "    assert X_train.shape == (60000, 32, 32, 3), \"X should have a dimension of (60000, 32, 32, 3)\"\n",
    "    assert y_train.shape == (60000,10), \"y should have a dimension of (60000,10)\"\n",
    "    assert X_test.shape == (10000, 32, 32, 3), \"X should have a dimension of (60000, 32, 32, 3)\"\n",
    "    assert y_test.shape == (10000,10), \"y should have a dimension of (60000,10)\"\n",
    "else:\n",
    "    print('Invalid selection!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "##\n",
    "# Prepare the train and test subsets if loaded from the server:\n",
    "#\n",
    "if data_location == 0:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = None, test_size = 10000)\n",
    "else:\n",
    "    None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Compute the flops of this model:\n",
    "#\n",
    "session = tensorflow.compat.v1.Session()\n",
    "graph = tensorflow.compat.v1.get_default_graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    with session.as_default():\n",
    "        models.model_concatenate(32,32,3,'concatenated')\n",
    "        run_meta = tensorflow.compat.v1.RunMetadata()\n",
    "        opts = tensorflow.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "        flops = tensorflow.compat.v1.profiler.profile(graph=graph,\n",
    "                                                      run_meta=run_meta, cmd = 'op', options=opts)\n",
    "\n",
    "tensorflow.compat.v1.reset_default_graph()\n",
    "\n",
    "##\n",
    "# Compute the memory usage of this model:\n",
    "#\n",
    "model, callbacks_list = models.model_concatenate(X_train.shape[1],X_train.shape[2],X_train.shape[3],'MNIST')\n",
    "memory_usage = profiler.memory_usage(model,64)\n",
    "\n",
    "##\n",
    "# Compute the required memory to store the model's weights\n",
    "#\n",
    "memory_weights = profiler.memory_weights(model)\n",
    "\n",
    "##\n",
    "# Test for model profiler:\n",
    "#\n",
    "if (not flops.total_float_ops) or (not memory_usage) or (not memory_weights):\n",
    "    raise SystemError('Error when executing this cell block.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "##\n",
    "# Train the model and store the execution time for evaluation:\n",
    "#\n",
    "start = time.time()\n",
    "history = model.fit(X_train, y_train, epochs = 100, verbose = 1, batch_size = 64, callbacks = callbacks_list,\n",
    "                         shuffle = True, validation_data = (X_test, y_test))\n",
    "end = time.time()\n",
    "duration_mnist = end - start\n",
    "tensorflow.keras.backend.clear_session()\n",
    "\n",
    "##\n",
    "# Test for concatenated model:\n",
    "#\n",
    "if not duration_mnist:\n",
    "    raise SystemError('Error when executing this cell block.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "##\n",
    "# Visualize the train/validation accuracy and loss after the training duration:\n",
    "#\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title(\"MNIST Accuracy\")\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc = 'upper left')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "###\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"MNIST Loss\")\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc = 'upper left')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Benchmark with Zalando MNIST dataset <a name = 'Test02'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "##\n",
    "# Load the Zalando MNIST dataset:\n",
    "#\n",
    "X_train, y_train = process_mnist.load_mnist('data/fashion', kind = 'train')\n",
    "X_test, y_test = process_mnist.load_mnist('data/fashion', kind = 't10k')\n",
    "\n",
    "\n",
    "##\n",
    "# Convert the input data into RGB image type and resize the resolution to 32x32:\n",
    "#\n",
    "X_train = process_mnist.resize_mnist(X_train, 28, 28, 32, 32)\n",
    "X_train = np.stack((X_train,) * 3, axis = -1)\n",
    "X_test = process_mnist.resize_mnist(X_test, 28, 28, 32, 32)\n",
    "X_test = np.stack((X_test,) * 3, axis = -1)\n",
    "\n",
    "##\n",
    "# One-hot encoding the output labels:\n",
    "#\n",
    "y_train = to_categorical(y_train, num_classes = 10)\n",
    "y_test = to_categorical(y_test, num_classes = 10)\n",
    "\n",
    "##\n",
    "# Test for data loading:\n",
    "#\n",
    "if (not np.any(X_train)) or (not np.any(X_test)) or (not np.any(y_train)) or (not np.any(y_test)):\n",
    "    raise SystemError('Error when executing this cell block.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "##\n",
    "# Sanity check for input and output dimensions:\n",
    "#\n",
    "assert X_train.shape == (60000,32,32,3), \"X_train should have a dimension of (60000,32,32,3)!\"\n",
    "assert X_test.shape == (10000,32,32,3), \"X_test should have a dimension of (10000,32,32,3)!\"\n",
    "assert y_train.shape == (60000,10), \"y_train should have a dimension of (60000,10)\"\n",
    "assert y_test.shape == (10000,10), \"y_test should have a dimension of (10000,10)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "###\n",
    "# Train the model and store the execution time for evaluation:\n",
    "#\n",
    "start = time.time()\n",
    "model, callbacks_list = models.model_concatenate(X_train.shape[1],X_train.shape[2],X_train.shape[3],'fashion')\n",
    "history = model.fit(X_train, y_train, epochs = 100, verbose = 1, batch_size = 64, callbacks = callbacks_list, shuffle = True, validation_data = (X_test, y_test))\n",
    "end = time.time()\n",
    "duration_fashion = end - start\n",
    "tensorflow.keras.backend.clear_session()\n",
    "\n",
    "##\n",
    "# Test for concatenated model:\n",
    "#\n",
    "if not duration_fashion:\n",
    "    raise SystemError('Error when executing this cell block.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "##\n",
    "# Visualize the train/validation accuracy and loss after the training duration:\n",
    "#\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title(\"Zalando Accuracy\")\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc = 'upper left')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "###\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"Zalando Loss\")\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc = 'upper left')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "##\n",
    "# Visualize the execution time on each dataset, respectively: \n",
    "#\n",
    "values = [round(duration_mnist,0) , round(duration_fashion,0)]\n",
    "names = ['MNIST', 'Zalando']\n",
    "\n",
    "plt.bar(names, values)\n",
    "plt.ylabel('Time')\n",
    "plt.grid(True)\n",
    "\n",
    "for index, data in enumerate(values):\n",
    "    plt.text(x = index , y = data + 1 , s = f\"{data}\" , fontdict = dict(fontsize = 12), ha = 'center')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "##\n",
    "# Save the duration results into a .csv file:\n",
    "#\n",
    "results = {'Test': ['MNIST','Fashion'],\n",
    "        'Duration (s)': values,\n",
    "        'FLOPS': flops.total_float_ops,\n",
    "        'Memory Usage for Model (GBytes)': memory_usage,\n",
    "        'Memory Usage for Weights (MBytes)': memory_weights\n",
    "          }\n",
    "df = pd.DataFrame(results, columns= ['Test', 'Duration (s)', 'FLOPS', \n",
    "                                     'Memory Usage for Model (GBytes)', 'Memory Usage for Weights (MBytes)'])\n",
    "df.to_csv('results/concatenate.csv', index = False)\n",
    "\n",
    "##\n",
    "# Test saving results:\n",
    "#\n",
    "if (not np.any(df)):\n",
    "    raise SystemError('Error when executing this cell block.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# (Optional): Automated debugging:\n",
    "#\n",
    "print('1. Total Execution Time for MNIST dataset:')\n",
    "if (duration_mnist):\n",
    "    print('Build:passing\\n')\n",
    "    \n",
    "print('2. Total Execution Time for Zalando MNIST dataset:')    \n",
    "if (duration_fashion):\n",
    "    print('Build:passing\\n')\n",
    "    \n",
    "print('3. The number of FLOPS in the model:')        \n",
    "if (flops.total_float_ops):\n",
    "    print('Build:passing\\n')\n",
    "\n",
    "print('4. Memory usage of the model:')    \n",
    "if (memory_usage):\n",
    "    print('Build:passing\\n')\n",
    "\n",
    "print('5. Memory required to store the model weights:')\n",
    "if (memory_weights):\n",
    "    print('Build:passing\\n')\n",
    "\n",
    "print('6. Save the results:')\n",
    "if (np.any(df)):\n",
    "    print('Build:passing\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
